{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2962825,"sourceType":"datasetVersion","datasetId":1752947},{"sourceId":2971722,"sourceType":"datasetVersion","datasetId":1752927}],"dockerImageVersionId":30145,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install langdetect","metadata":{"_uuid":"95258832-70a8-4670-8a0f-73b69bb7f1be","_cell_guid":"0d298397-7950-4fdd-84e2-734671922b79","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:35.837052Z","iopub.execute_input":"2022-09-10T03:42:35.837607Z","iopub.status.idle":"2022-09-10T03:42:42.296378Z","shell.execute_reply.started":"2022-09-10T03:42:35.837565Z","shell.execute_reply":"2022-09-10T03:42:42.295269Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import path\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nimport pylab as py\nfrom scipy.sparse import hstack\nfrom scipy.sparse import coo_matrix\nfrom tqdm import tqdm\nfrom scipy import sparse\nimport csv, random, numpy, os, re, nltk, scipy, gensim\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import tree\nfrom langdetect import detect\nfrom sklearn.ensemble import RandomForestClassifier\nfrom csv import DictReader\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nimport math\nimport re\nfrom collections import Counter\n# import score","metadata":{"_uuid":"0e8b3452-78ab-4a8e-8091-3a2cae6011e1","_cell_guid":"e5f1ac14-718f-4b55-ba6f-ac9549149a4f","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.298737Z","iopub.execute_input":"2022-09-10T03:42:42.298947Z","iopub.status.idle":"2022-09-10T03:42:42.306902Z","shell.execute_reply.started":"2022-09-10T03:42:42.298923Z","shell.execute_reply":"2022-09-10T03:42:42.306276Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataSet():\n    def __init__(self, path=\"../input/d/abdullahalmazid/data-mazid/\"):\n        self.path = path\n\n        print(\"Reading dataset\")\n        bodies = \"train_bodies_zv1.csv\"\n        stances = \"train_stances_zv2.csv\"\n\n        self.stances = self.read(stances)\n        self.stances_v2 = self.read(stances)\n        articles = self.read(bodies)\n        self.articles = dict()\n\n        #make the body ID an integer value\n        for s in self.stances:\n            s['Body ID'] = int(s['Body ID'])\n\n        #copy all bodies into a dictionary\n        for article in articles:\n            self.articles[int(article['Body ID'])] = article['articleBody']\n            \n        #make the body ID an integer value\n        for s in self.stances_v2:\n            s['Body'] = self.articles[int(s['Body ID'])]\n            \n\n        print(\"Total stances: \" + str(len(self.stances)))\n        print(\"Total bodies: \" + str(len(self.articles)))\n\n\n\n    def read(self,filename):\n        rows = []\n        with open(self.path + \"/\" + filename, \"r\", encoding='utf-8') as table:\n            r = DictReader(table)\n\n            for line in r:\n                rows.append(line)\n        return rows","metadata":{"_uuid":"42d463ea-9931-413e-b2aa-d506c4e66f96","_cell_guid":"31ad7e0c-c763-41fe-adb2-59275cde162e","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.308204Z","iopub.execute_input":"2022-09-10T03:42:42.308478Z","iopub.status.idle":"2022-09-10T03:42:42.321963Z","shell.execute_reply.started":"2022-09-10T03:42:42.308433Z","shell.execute_reply":"2022-09-10T03:42:42.321354Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DataSet()","metadata":{"_uuid":"e52d2c02-2e70-43e4-8cca-93912d847fb0","_cell_guid":"3694be48-5864-4de7-b014-2f9948485cbd","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.323432Z","iopub.execute_input":"2022-09-10T03:42:42.323715Z","iopub.status.idle":"2022-09-10T03:42:42.388883Z","shell.execute_reply.started":"2022-09-10T03:42:42.323684Z","shell.execute_reply":"2022-09-10T03:42:42.388365Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WORD = re.compile(r\"\\w+\")\n\ndef get_cosine(vec1, vec2):\n    intersection = set(vec1.keys()) & set(vec2.keys())\n    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n\n    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n\n    if not denominator:\n        return 0.0\n    else:\n        return float(numerator) / denominator\n\n\ndef text_to_vector(text):\n    words = WORD.findall(text)\n    return Counter(words)\n\n\ndef jaccard_similarity(query, document):\n    intersection = set(query).intersection(set(document))\n    union = set(query).union(set(document))\n    return len(intersection)/len(union)","metadata":{"_uuid":"3e6fc756-275a-43eb-a165-ee5e5e714528","_cell_guid":"80b2eac9-4d9d-4368-8884-f68d30052b38","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.391346Z","iopub.execute_input":"2022-09-10T03:42:42.391576Z","iopub.status.idle":"2022-09-10T03:42:42.399094Z","shell.execute_reply.started":"2022-09-10T03:42:42.391552Z","shell.execute_reply":"2022-09-10T03:42:42.398584Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_ids(file,base=\"../input/idsmazid\"):\n    ids = []\n    with open(base+\"/\"+file,\"r\") as f:\n        for line in f:\n            ids.append(int(line))\n        return ids\n    \ndef split(dataset, base=\"../input/idsmazid\"):\n    if not (os.path.exists(base+\"/\"+\"training_ids_zv1.txt\")\n            and os.path.exists(base+\"/\"+\"dev_ids_zv1.txt\") and os.path.exists(base+\"/\"+\"test_ids_zv1.txt\")):\n        raise Exception(\"There is an error and the dataset reader cannot find the \"\n                        \"{training_ids|test_ids|dev_ids}.txt file. Please make sure your python paths \"\n                        \"are configured correctly\")\n\n    training_ids = read_ids(\"training_ids_zv1.txt\",base)\n    dev_ids = read_ids(\"dev_ids_zv1.txt\",base)\n    test_ids = read_ids(\"test_ids_zv1.txt\",base)\n    \n    print (test_ids)\n    #return the stances that meet these criteria\n    training_stances = []\n    dev_stances = []\n    test_stances = []\n    test_datapoint_index = []\n    \n    index=0;\n    for stance in dataset.stances:\n        if stance['Body ID'] in training_ids:\n            training_stances.append(stance)\n        if stance['Body ID'] in dev_ids:\n            dev_stances.append(stance)\n        if stance['Body ID'] in test_ids:\n            test_stances.append(stance)\n            test_datapoint_index.append(index)\n        \n        index = index + 1\n\n    return {\"training\":training_stances, \"dev\":dev_stances, \"test\": test_stances, \"test_datapoint_index\": test_datapoint_index}","metadata":{"_uuid":"def8293b-a906-4c01-b3eb-1f0c61cab0a8","_cell_guid":"1771610f-8db9-46fb-ba7f-708faa8cc3de","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.400262Z","iopub.execute_input":"2022-09-10T03:42:42.400473Z","iopub.status.idle":"2022-09-10T03:42:42.412247Z","shell.execute_reply.started":"2022-09-10T03:42:42.400449Z","shell.execute_reply":"2022-09-10T03:42:42.411219Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n[1] Loading data..\")\ndata_splits = split(dataset)\n# in the format: Stance, Headline, BodyID\ntraining_data = data_splits['training']\ndev_data = data_splits['dev']\ntest_data = data_splits['test'] # currently 0 test points\ntest_datapoint_index = data_splits['test_datapoint_index']\n# Change the number of training examples used.\nN = int(len(training_data) * 1.0)\ntraining_data = training_data[:N]\n\nprint(\"\\t-Training size:\\t\", len(training_data))\nprint(\"\\t-Dev size:\\t\", len(dev_data))\nprint(\"\\t-Test data:\\t\", len(test_data)) #184\n#for test data id starts at 31 and ends at 45\nlen(dataset.stances)\nlen(test_datapoint_index)","metadata":{"_uuid":"10720186-ca31-472d-9d07-981720385229","_cell_guid":"faa4c335-2734-434a-995e-42b56db8e7e5","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.415790Z","iopub.execute_input":"2022-09-10T03:42:42.415993Z","iopub.status.idle":"2022-09-10T03:42:42.444965Z","shell.execute_reply.started":"2022-09-10T03:42:42.415969Z","shell.execute_reply":"2022-09-10T03:42:42.444500Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard_similarity(query, document):\n    intersection = set(query).intersection(set(document))\n    union = set(query).union(set(document))\n    return len(intersection)/len(union)\n\ndef calculateUnrelatedStanceAccuracy_v1(threshold, rangeN):\n    matchCnt = 0\n    unrelatedCnt=0\n    ypred=np.zeros(rangeN)\n    minm = 0\n    unmatch = 0\n    relatedCnt = 0\n    mat = np.zeros((2,2))\n\n    for i in range(0,rangeN):\n        vector1 = text_to_vector(dataset.stances_v2[i]['Headline'])\n        vector2 = text_to_vector(dataset.stances_v2[i]['Body'])\n\n        cos_scores = get_cosine(vector1, vector2)\n        #cos_scores = jaccard_similarity(vector1, vector2)\n        #print(dataset.stances_v2[i]['Stance'])\n        if dataset.stances_v2[i]['Stance'] == 'unrelated':\n            #print(cos_scores)\n            unrelatedCnt = unrelatedCnt + 1\n        else:\n            #print(cos_scores)\n            relatedCnt += 1\n            if cos_scores < threshold:\n                minm += 1\n            \n        if cos_scores < threshold:\n            ypred[i]= 1\n            if dataset.stances_v2[i]['Stance'] == 'unrelated':\n               mat[0][0] += 1\n               matchCnt+= 1\n            else:\n               mat[0][1] += 1\n        else:\n            if dataset.stances_v2[i]['Stance'] != 'unrelated':\n               mat[1][1] += 1\n               unmatch += 1\n            else:\n               mat[1][0] += 1\n            \n        \n    #print(unrelatedCnt)  \n    mat[0][0] = mat[0][0]/unrelatedCnt\n    mat[0][1] = mat[0][1]/relatedCnt\n    mat[1][0] = mat[1][0]/unrelatedCnt\n    mat[1][1] = mat[1][1]/relatedCnt\n    print(minm)\n    return matchCnt/unrelatedCnt,unmatch/relatedCnt,mat,ypred","metadata":{"_uuid":"bc1c9c8f-1332-4d4a-93a6-12b3f28b4b3b","_cell_guid":"4aad88f3-c2a0-4eae-b1d7-8abd310dafa7","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.446371Z","iopub.execute_input":"2022-09-10T03:42:42.446529Z","iopub.status.idle":"2022-09-10T03:42:42.457904Z","shell.execute_reply.started":"2022-09-10T03:42:42.446505Z","shell.execute_reply":"2022-09-10T03:42:42.456841Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # jaccard_similarity optimal point- (threshold: 0.0755, accuracy: 0.8830065359477124)\n # get_cosine - (threshold: 0.227, accuracy: 0.8911764705882353)\n\ngAccuracyForUnrelatedStances,gAccuracyForRelatedStances,mat,unrelatedPred = calculateUnrelatedStanceAccuracy_v1(0.22, len(dataset.stances_v2))\nprint (\"Accuracy: \",gAccuracyForUnrelatedStances)\nprint (\"Accuracy: \",gAccuracyForRelatedStances)\nprint ( )\nprint(unrelatedPred[3])\nprint ( )\nlabels = [\"Unrelated\",\"Related\"]\nfig, ax = plt.subplots(figsize=(11,11))  \nsns.heatmap(mat, square=True, annot=True, cbar=True,cmap=\"icefire\",fmt=\".2%\",\n            xticklabels=labels,yticklabels=labels,linewidths=.3, ax=ax)\n    \nplt.xlabel('True label')\nplt.ylabel('Predicted label');","metadata":{"_uuid":"9e02fd33-5bbb-470e-85b0-c8d6f9657754","_cell_guid":"c745d1fa-7981-4941-907c-352cf50453e4","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.459348Z","iopub.execute_input":"2022-09-10T03:42:42.459556Z","iopub.status.idle":"2022-09-10T03:42:42.840193Z","shell.execute_reply.started":"2022-09-10T03:42:42.459531Z","shell.execute_reply":"2022-09-10T03:42:42.839084Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the bodies of training data points\ndef get_bodies(data):\n    bodies = []\n    for i in range(len(data)):\n        bodies.append(dataset.articles[data[i]['Body ID']])\n    return bodies\n\n# Get the headlines of training data points\ndef get_headlines(data):\n    headlines = []\n    for i in range(len(data)):\n        headlines.append(data[i]['Headline'])\n    return headlines","metadata":{"_uuid":"399fe2e2-ab89-46fd-bb07-b06075882b81","_cell_guid":"e6e3adc9-3f6d-41b6-b97f-800b8a3196bf","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.842541Z","iopub.execute_input":"2022-09-10T03:42:42.842727Z","iopub.status.idle":"2022-09-10T03:42:42.848669Z","shell.execute_reply.started":"2022-09-10T03:42:42.842703Z","shell.execute_reply":"2022-09-10T03:42:42.847727Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get bodies and headlines for dev and training data\ntraining_bodies = get_bodies(training_data)\ntraining_headlines = get_headlines(training_data)\ndev_bodies = get_bodies(dev_data)\ndev_headlines = get_headlines(dev_data)\ntest_bodies = get_bodies(test_data)\ntest_headlines = get_headlines(test_data)\n\nprint(len(training_bodies))\nprint(len(training_headlines))\nprint(len(dev_bodies))\nprint(len(dev_headlines))\nprint(len(test_bodies))\nprint(len(test_headlines))","metadata":{"_uuid":"e31e735f-0bf1-4a24-8736-63c9b4768dec","_cell_guid":"3e1eecb4-27d7-4652-952e-a34f05a8590a","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.849797Z","iopub.execute_input":"2022-09-10T03:42:42.850021Z","iopub.status.idle":"2022-09-10T03:42:42.864890Z","shell.execute_reply.started":"2022-09-10T03:42:42.849994Z","shell.execute_reply":"2022-09-10T03:42:42.863417Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for extracting tf-idf vectors (for both the bodies and the headlines).\n# https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments\n\ndef extract_tfidf(training_headlines, training_bodies, dev_headlines=\"\", dev_bodies=\"\", test_headlines=\"\", test_bodies=\"\"):\n    # Body vectorisation\n    body_vectorizer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, stop_words='english')#, max_features=1024)\n    bodies_tfidf = body_vectorizer.fit_transform(training_bodies)\n\n    # Headline vectorisation\n    headline_vectorizer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, stop_words='english')#, max_features=1024)\n    headlines_tfidf = headline_vectorizer.fit_transform(training_headlines)\n\n    # Tranform dev/test bodies and headlines using the trained vectorizer (trained on training data)\n    bodies_tfidf_dev = body_vectorizer.transform(dev_bodies)\n    headlines_tfidf_dev = headline_vectorizer.transform(dev_headlines)\n\n    bodies_tfidf_test = body_vectorizer.transform(test_bodies)\n    headlines_tfidf_test = headline_vectorizer.transform(test_headlines)\n    \n    feature_names = np.array(body_vectorizer.get_feature_names())\n    sorted_by_idf = np.argsort(body_vectorizer.idf_) \n    print('Features with lowest and highest idf in the body vector:\\n')\n    # The token which appears maximum times but it is also in all documents, has its idf the lowest\n    print(\"Features with lowest idf:\\n{}\".format(\n    feature_names[sorted_by_idf[:10]]))\n    # The tokens can have the most idf weight because they are the only tokens that appear in one document only\n    print(\"\\nFeatures with highest idf:\\n{}\".format(\n    feature_names[sorted_by_idf[-10:]]))\n\n    # Combine body_tfdif with headline_tfidf for every data point. \n    training_tfidf = scipy.sparse.hstack([bodies_tfidf, headlines_tfidf])\n    dev_tfidf = scipy.sparse.hstack([bodies_tfidf_dev, headlines_tfidf_dev])\n    test_tfidf = scipy.sparse.hstack([bodies_tfidf_test, headlines_tfidf_test])\n\n    return training_tfidf, dev_tfidf, test_tfidf","metadata":{"_uuid":"cc3fd48e-d8f1-4570-acd0-0e55a31a1363","_cell_guid":"d19f2bd6-e43a-4a4b-8f81-6bc9df717778","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.866745Z","iopub.execute_input":"2022-09-10T03:42:42.867041Z","iopub.status.idle":"2022-09-10T03:42:42.876112Z","shell.execute_reply.started":"2022-09-10T03:42:42.867015Z","shell.execute_reply":"2022-09-10T03:42:42.875576Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lemmatizer = nltk.WordNetLemmatizer()\n\n# Tokenisation, Normalisation, Capitalisation, Non-alphanumeric removal, Stemming-Lemmatization\ndef preprocess(string):\n    # to lowercase, non-alphanumeric removal\n    step1 = \" \".join(re.findall(r'\\w+', string, flags=re.UNICODE)).lower()\n    step2 = [lemmatizer.lemmatize(t).lower() for t in nltk.word_tokenize(step1)]\n\n    return step2\n\n# Function for extracting word overlap\ndef extract_word_overlap(headlines, bodies):\n    word_overlap = []\n    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n        preprocess_headline = preprocess(headline)\n        preprocess_body = preprocess(body)\n        \n        # Lenght of common words b/w body and headline / Length of all the words of body & headline\n        features = len(set(preprocess_headline).intersection(preprocess_body)) / float(len(set(preprocess_headline).union(preprocess_body)))\n        word_overlap.append(features)\n        \n        # Convert the list to a sparse matrix (in order to concatenate the cos sim with other features)\n        word_overlap_sparse = scipy.sparse.coo_matrix(numpy.array(word_overlap)) \n    return word_overlap_sparse","metadata":{"_uuid":"d5e72514-256a-40f4-bd3d-b625ea86d41a","_cell_guid":"bf64827e-7423-4ada-a0fa-f9e820f7fe88","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.877362Z","iopub.execute_input":"2022-09-10T03:42:42.877666Z","iopub.status.idle":"2022-09-10T03:42:42.894467Z","shell.execute_reply.started":"2022-09-10T03:42:42.877599Z","shell.execute_reply":"2022-09-10T03:42:42.893647Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for extracting the cosine similarity between bodies and headlines. \ndef extract_cosine_similarity(headlines, bodies):\n    vectorizer = TfidfVectorizer(ngram_range=(1,2), lowercase=True, stop_words='english')#, max_features=1024)\n    \n    cos_sim_features = []\n    for i in range(0, len(bodies)):\n        body_vs_headline = []\n        body_vs_headline.append(bodies[i])\n        body_vs_headline.append(headlines[i])\n        tfidf = vectorizer.fit_transform(body_vs_headline)\n        \n        cosine_similarity = (tfidf * tfidf.T).A\n        cos_sim_features.append(cosine_similarity[0][1])\n\n    # Convert the list to a sparse matrix (in order to concatenate the cos sim with other features)\n    cos_sim_array = scipy.sparse.coo_matrix(numpy.array(cos_sim_features)) \n\n    return cos_sim_array","metadata":{"_uuid":"65d015ee-8313-4cdb-8446-df8568318bb0","_cell_guid":"261f997a-93fe-4792-a61b-419c642b9589","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.895951Z","iopub.execute_input":"2022-09-10T03:42:42.896354Z","iopub.status.idle":"2022-09-10T03:42:42.913007Z","shell.execute_reply.started":"2022-09-10T03:42:42.896299Z","shell.execute_reply":"2022-09-10T03:42:42.911815Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for combining features of various types (lists, coo_matrix, np.array etc.)\ndef combine_features(tfidf_vectors, cosine_similarity, word_overlap):\n    combined_features =  sparse.bmat([[tfidf_vectors, word_overlap.T, cosine_similarity.T]])\n    return combined_features","metadata":{"_uuid":"abaf58ca-179e-494b-9cad-12960d3fb075","_cell_guid":"6686a8be-fb37-4614-b6f2-3d4cae6d8118","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.914420Z","iopub.execute_input":"2022-09-10T03:42:42.914627Z","iopub.status.idle":"2022-09-10T03:42:42.927542Z","shell.execute_reply.started":"2022-09-10T03:42:42.914599Z","shell.execute_reply":"2022-09-10T03:42:42.926707Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for extracting features\n# Feautres: 1) Word Overlap, 2) TF-IDF vectors, 3) Cosine similarity, 4) Word embeddings\ndef extract_features(train, dev, test):\n# Get bodies and headlines for dev and training data\n    training_bodies = get_bodies(training_data)\n    training_headlines = get_headlines(training_data)\n    dev_bodies = get_bodies(dev_data)\n    dev_headlines = get_headlines(dev_data)\n    test_bodies = get_bodies(test_data)\n    test_headlines = get_headlines(test_data)\n\n    # Extract tfidf vectors\n    print(\"\\t-Extracting tfidf vectors..\")\n    training_tfidf, dev_tfidf, test_tfidf = extract_tfidf(training_headlines, training_bodies, dev_headlines, dev_bodies, test_headlines, test_bodies)\n    print(\"\\t-Tfidf vectors extracted..\")\n\n    # Extract word overlap \n    print(\"\\t-Extracting word overlap..\")\n    training_overlap = extract_word_overlap(training_headlines, training_bodies)\n    dev_overlap = extract_word_overlap(dev_headlines, dev_bodies)\n    test_overlap = extract_word_overlap(test_headlines, test_bodies)\n    print(\"\\t-Word overlap extracted..\")\n\n#     # Extract cosine similarity between bodies and headlines. \n    print(\"\\t-Extracting cosine similarity..\")\n    training_cos = extract_cosine_similarity(training_headlines, training_bodies)\n    dev_cos = extract_cosine_similarity(dev_headlines, dev_bodies)\n    test_cos = extract_cosine_similarity(test_headlines, test_bodies)\n    print(\"\\t-Cosine similarity extracted..\")\n\n    # Combine the features\n    training_features = combine_features(training_tfidf, training_cos, training_overlap)\n    dev_features = combine_features(dev_tfidf, dev_cos, dev_overlap)\n    test_features = combine_features(test_tfidf, test_cos, test_overlap)\n    print(\"\\t-Combined features returned..\")\n\n    return training_features, dev_features, test_features","metadata":{"_uuid":"48c999dc-ac8d-419f-a282-1fc8216a32c6","_cell_guid":"2b1e16a6-a1fb-4b9b-a67a-d588c9fa034c","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.929021Z","iopub.execute_input":"2022-09-10T03:42:42.929567Z","iopub.status.idle":"2022-09-10T03:42:42.947191Z","shell.execute_reply.started":"2022-09-10T03:42:42.929531Z","shell.execute_reply":"2022-09-10T03:42:42.945940Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature extraction\nprint(\"[2] Extracting features.. \")\n# extract_features(training_data, dev_data, test_data)\ntraining_features, dev_features, test_features = extract_features(training_data, dev_data, test_data)","metadata":{"_uuid":"e4fe9b64-aa22-4597-8a11-273cc323e0f1","_cell_guid":"cd1caf8d-2934-447c-b0d8-c6eeeceedbe3","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:42.948627Z","iopub.execute_input":"2022-09-10T03:42:42.948995Z","iopub.status.idle":"2022-09-10T03:42:49.503842Z","shell.execute_reply.started":"2022-09-10T03:42:42.948960Z","shell.execute_reply":"2022-09-10T03:42:49.502689Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_v2 = ['agree', 'disagree', 'discuss', 'unrelated']\n\ndef report_score_v2(test,pred,algo):\n    #accuracy calculation\n    accuracy = accuracy_score(test,pred)\n    \n    #print('\\n Accuracy_score for %s = %s \\n'%(algo,accuracy))\n    \n    #confusion_matrix\n    mat = confusion_matrix(test,pred)\n    \n    #print ( 'Confusion Matrix Start' )\n    #print ( mat )\n    #print ( 'Confusion Matrix End' )\n    \n    agreeAC = mat[0][0]/(mat[0][0]+mat[0][1]+mat[0][2]+mat[0][3])\n    disagreeAC = mat[1][1]/(mat[1][0]+mat[1][1]+mat[1][2]+mat[1][3])\n    discussAC = mat[2][2]/(mat[2][0]+mat[2][1]+mat[2][2]+mat[2][3])\n    unrelatedAC = gAccuracyForUnrelatedStances\n\n    print ( \"Total Accuracy: \",100*(agreeAC + disagreeAC + unrelatedAC) /3 )\n    \n    fig, ax = plt.subplots(figsize=(11,11))  \n    ax.set_title(\"Confusion Matrix for %s\" %algo)\n    sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,cmap=\"icefire\",\n                xticklabels=classes,yticklabels=classes,linewidths=.3, ax=ax,annot_kws={\"fontsize\":12})\n    plt.xlabel('True label')\n    plt.ylabel('Predicted label');\n\n    #classification report\n    cls = classification_report(test,pred, target_names=classes)\n    print(cls)","metadata":{"_uuid":"046d83e2-507e-4002-8f5c-9aaf934bd197","_cell_guid":"87519761-ba3c-458d-9e1b-cb536ee900ed","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:49.505161Z","iopub.execute_input":"2022-09-10T03:42:49.505413Z","iopub.status.idle":"2022-09-10T03:42:49.516205Z","shell.execute_reply.started":"2022-09-10T03:42:49.505383Z","shell.execute_reply":"2022-09-10T03:42:49.514787Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['agree', 'disagree', 'discuss']\nclasses2 = ['agree', 'disagree', 'discuss','unrelated']\n\ndef report_score(test,pred,algo):\n    #accuracy calculation\n    accuracy = accuracy_score(test,pred)\n    print('\\n Accuracy_score for %s = %s \\n'%(algo,accuracy))\n    \n    #confusion_matrix\n    mat = confusion_matrix(test,pred)\n    \n    print ('Confusion Matrix Start')\n    print (mat)\n    print ('Confusion Matrix End')\n    \n    agreeAC = mat[0][0]/(mat[0][0]+mat[0][1]+mat[0][2]+mat[0][3])\n    disagreeAC = mat[1][1]/(mat[1][0]+mat[1][1]+mat[1][2]+mat[1][3])\n    discussAC = mat[2][2]/(mat[2][0]+mat[2][1]+mat[2][2]+mat[2][3])\n    unrelatedAC = gAccuracyForUnrelatedStances\n    \n    rel = np.zeros((3,3))\n    \n    for i in range(0,3):\n        for j in range(0,3):\n            rel[i][j] = mat[i][j]/(mat[i][0]+mat[i][1]+mat[i][2]+mat[i][3])\n    \n    \n\n    \n    print ('New AC start')\n    print(\"Agree Accuracy: \",agreeAC*100)\n    print(\"Disagree Accuracy: \",disagreeAC*100)\n    print(\"Discuss Accuracy: \",discussAC*100)\n    print(\"unrelated Accuracy: \",unrelatedAC*100)\n    print(\"-------------------------------------\")\n    print (\"Total Accuracy: \",100*(agreeAC + disagreeAC + unrelatedAC) /3)\n    print ('New AC End')\n    print(rel)\n    fig, ax = plt.subplots(figsize=(11,11))  \n    ax.set_title(\"Confusion Matrix for %s\" %algo)\n    sns.heatmap(rel, square=True, annot=True, cbar=True,cmap=\"icefire\",fmt=\".2%\",\n                xticklabels=classes,yticklabels=classes,linewidths=.3, ax=ax,annot_kws={\"fontsize\":20})\n    \n    plt.xlabel('True label')\n    plt.ylabel('Predicted label');\n\n    #classification report\n    cls = classification_report(test,pred, target_names=classes2)\n    print(cls)","metadata":{"_uuid":"b913ed7d-e407-425c-8b14-e394e3bc351a","_cell_guid":"ef0805e2-3ce2-4cea-8b36-80f1bb05e8b8","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:49.517659Z","iopub.execute_input":"2022-09-10T03:42:49.517899Z","iopub.status.idle":"2022-09-10T03:42:49.531660Z","shell.execute_reply.started":"2022-09-10T03:42:49.517874Z","shell.execute_reply":"2022-09-10T03:42:49.531037Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_output(y_pred_lr,unrelatedPred):\n    for i in range(0,len(y_pred_lr)):\n        if y_pred_lr[i] != \"unrelated\" and unrelatedPred[test_datapoint_index[i]] == 1:\n            y_pred_lr[i] = \"unrelated\"\n    return y_pred_lr","metadata":{"_uuid":"76aa60d4-5478-449e-a231-fb763b040333","_cell_guid":"a6b42beb-efd7-45ef-a5a8-d6764f2a7554","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:49.532783Z","iopub.execute_input":"2022-09-10T03:42:49.533158Z","iopub.status.idle":"2022-09-10T03:42:49.544135Z","shell.execute_reply.started":"2022-09-10T03:42:49.533133Z","shell.execute_reply":"2022-09-10T03:42:49.543410Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating targets\ntargets_tr = [a['Stance'] for a in training_data]\ntargets_dev = [a['Stance'] for a in dev_data]\ntargets_test = [a['Stance'] for a in test_data]","metadata":{"_uuid":"7d81210c-e19d-4efe-8ff6-a7e34cd059f1","_cell_guid":"4588af7b-06fb-4199-bcbb-3929134a94dc","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:49.545388Z","iopub.execute_input":"2022-09-10T03:42:49.545576Z","iopub.status.idle":"2022-09-10T03:42:49.557722Z","shell.execute_reply.started":"2022-09-10T03:42:49.545551Z","shell.execute_reply":"2022-09-10T03:42:49.556920Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def change(f):\n    if f == 'unrelated':\n        return 0\n    elif f == 'disagree':\n        return 1\n    elif f == 'discuss':\n        return 2\n    elif f == 'agree':\n        return 3\n    else:\n        return 0\n\ny = [change(x) for x in targets_tr]\ny_test = [change(x) for x in targets_test]","metadata":{"_uuid":"9b707695-a70d-4591-b13b-a3655e9fd91b","_cell_guid":"674376dc-71f0-4902-aabc-e166f42a5c57","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:49.558837Z","iopub.execute_input":"2022-09-10T03:42:49.559010Z","iopub.status.idle":"2022-09-10T03:42:49.579018Z","shell.execute_reply.started":"2022-09-10T03:42:49.558988Z","shell.execute_reply":"2022-09-10T03:42:49.578026Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(self, text):\n        predicted = self.logR_pipeline.predict([text])\n        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n        return bool(predicted), float(predicedProb)\n    \n#print (dataset.stances_v2[32])","metadata":{"_uuid":"acf812f7-1b0b-4e51-8e88-089331a62893","_cell_guid":"213f7120-95eb-46a3-a21c-5d2b989050da","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:49.580619Z","iopub.execute_input":"2022-09-10T03:42:49.580929Z","iopub.status.idle":"2022-09-10T03:42:49.597401Z","shell.execute_reply.started":"2022-09-10T03:42:49.580831Z","shell.execute_reply":"2022-09-10T03:42:49.596391Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting model\nprint(\"[3] Fitting model..\")\nprint(\"\\t-Logistic Regression\")\nlr = LogisticRegression(penalty='elasticnet',C = 0.4, class_weight='balanced', solver='saga', max_iter=150, l1_ratio=0.7) \ny_pred_lr = lr.fit(training_features, targets_tr).predict(test_features)\n#print (unrelatedPred)\n#print(len(y_pred_lr))\n#print(len(unrelatedPred))\n#y_pred_lr = process_output(y_pred_lr,unrelatedPred)\n\n# Evaluation\nprint(\"[4] Evaluating model..\")\nreport_score(targets_test, y_pred_lr,'Logistic Regression')\nprint(\"\\t-Done with Logistic Regression\")\n\n#highest:55.17%","metadata":{"_uuid":"28a30a9a-324c-4847-a3bb-57da813b104a","_cell_guid":"49b14790-dd40-4bff-96bc-0942c64cc8ce","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:49.598931Z","iopub.execute_input":"2022-09-10T03:42:49.599134Z","iopub.status.idle":"2022-09-10T03:42:51.569921Z","shell.execute_reply.started":"2022-09-10T03:42:49.599109Z","shell.execute_reply":"2022-09-10T03:42:51.569144Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\t-Random Forest Classifier\")\nrf = RandomForestClassifier(n_estimators=20, random_state=19,criterion='gini',min_samples_leaf=1)\ny_pred_rf = rf.fit(training_features, targets_tr).predict(test_features)\n#y_pred_rf= process_output(y_pred_rf,unrelatedPred)\nprint(\"[4] Evaluating model..\")\nreport_score(targets_test, y_pred_rf,'Random Forest Classifier')\nprint(\"\\t-Done with Random Forest Classifier\")","metadata":{"_uuid":"c0eef108-eb70-4777-b4af-bcc8a2891566","_cell_guid":"e2ee2acc-0acb-434f-9285-bae16277c265","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:51.571119Z","iopub.execute_input":"2022-09-10T03:42:51.571395Z","iopub.status.idle":"2022-09-10T03:42:52.381941Z","shell.execute_reply.started":"2022-09-10T03:42:51.571360Z","shell.execute_reply":"2022-09-10T03:42:52.381123Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"[3] Fitting model..\")\nprint(\"\\t-Multinomial Naive Bayes\")\nnb = MultinomialNB(alpha=0.09, class_prior=(0.5,0.5,0.1,0.0), fit_prior=True)\n# nb = MultinomialNB(alpha=0.09, class_prior=(0.5,0.5,0.1,0.0), fit_prior=True) best\ny_pred_nb = nb.fit(training_features, targets_tr).predict(test_features)\n#y_pred_nb= process_output(y_pred_nb,unrelatedPred)\n\nprint(\"[4] Evaluating model..\")\nreport_score(targets_test, y_pred_nb,'Multinomial Naive Bayes')\nprint(\"\\t-Done with Multinomial Naive Bayes\")","metadata":{"_uuid":"040a524c-3a09-4b5b-a922-fd2ebf3bb530","_cell_guid":"cb84e1dc-a194-4a93-b736-73dc8d820392","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:48:36.284551Z","iopub.execute_input":"2022-09-10T03:48:36.284801Z","iopub.status.idle":"2022-09-10T03:48:36.568498Z","shell.execute_reply.started":"2022-09-10T03:48:36.284776Z","shell.execute_reply":"2022-09-10T03:48:36.567789Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"[3] Fitting model..\")\nprint(\"\\t-XGBoost Classifier\")\nxgb = XGBClassifier(learning_rate=0.05,n_estimators=100,random_state=2,subsample=1.0,warm_start=True)\ny_pred_xgb = xgb.fit(training_features, targets_tr).predict(test_features)\n#y_pred_xgb = process_output(y_pred_xgb, unrelatedPred)\n# Evaluation\nprint(\"[4] Evaluating model..\")\nreport_score(targets_test, y_pred_xgb,'XGBoost')\nprint(\"\\t-Done with XGBoost Classifier\")","metadata":{"_uuid":"fc2b8f23-fec3-4207-8f6e-d2a8210c9b88","_cell_guid":"56afe574-893e-4510-a47c-303cfba19b5b","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:52.669984Z","iopub.execute_input":"2022-09-10T03:42:52.670219Z","iopub.status.idle":"2022-09-10T03:42:57.012770Z","shell.execute_reply.started":"2022-09-10T03:42:52.670186Z","shell.execute_reply":"2022-09-10T03:42:57.012065Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_ensemble2 = []\n\nstances = {\"agree\":0,\"disagree\":1,\"discuss\":2,\"unrelated\":3}\nclass_id = {0:\"agree\",1:\"disagree\",2:\"discuss\",3:\"unrelated\"}\nweights = [0.1,0.5,0.3,1.9]\n\n#Assign weights dyanamically based on the degree to which they could predict the stances\nweight_lr = {\"agree\":0.3762,\"disagree\":0.3077,\"discuss\":1.15,\"unrelated\":0.0}\nweight_nb = {\"agree\":0.7738,\"disagree\":0.7289,\"discuss\":0.3588,\"unrelated\":0.0}\nweight_rf = {\"agree\":0.9786,\"disagree\":0.0526,\"discuss\":0.0588,\"unrelated\":0.0}\nweight_xgb = {\"agree\":0.7143,\"disagree\":0.8276, \"discuss\":0.0588,\"unrelated\":0.0}\n\nfor i in range(len(targets_test)):\n  classp = np.zeros(4)\n  maxg = 0\n  max_weight = 0\n  \n  classp[stances[y_pred_lr[i]]] += weight_lr[y_pred_lr[i]]\n  classp[stances[y_pred_rf[i]]] += weight_rf[y_pred_rf[i]]\n  classp[stances[y_pred_nb[i]]] += weight_nb[y_pred_nb[i]]\n  classp[stances[y_pred_xgb[i]]] += weight_xgb[y_pred_xgb[i]]\n    \n  for j in range(len(classp)):\n    if classp[j] > max_weight:\n      maxg = j\n      max_weight = classp[j]\n  y_pred_ensemble2.append(class_id[maxg])\n\n#y_pred_ensemble2 = process_output(y_pred_ensemble2,unrelatedPred)\n#print(\"Accuracy:\",accuracy_score(targets_test,y_pred_ensemble2)*100)\nreport_score(targets_test, y_pred_ensemble2,'Ensemble')","metadata":{"_uuid":"652412a9-2b4e-4552-9b0f-ed0a635b3d4a","_cell_guid":"ceb043c8-5760-45d4-8521-f819ae940c58","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:57.015438Z","iopub.execute_input":"2022-09-10T03:42:57.015633Z","iopub.status.idle":"2022-09-10T03:42:57.276876Z","shell.execute_reply.started":"2022-09-10T03:42:57.015609Z","shell.execute_reply":"2022-09-10T03:42:57.275665Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#weighted accuracy computation\nweight_en = {\"agree\": 5,\"disagree\": 1,\"discuss\": 0.2,\"unrelated\": 0.2}\naccuracy_en = 0.0\naccurate_weight_total = 0.0\nweight_total = 0.0\n\nfor i in range(len(y_pred_ensemble2)):\n    if targets_test[i] != \"unrelated\":\n        weight_total += weight_en[targets_test[i]]\n        if targets_test[i] == y_pred_ensemble2[i]:\n            accurate_weight_total += weight_en[targets_test[i]]\n             \nprint (accurate_weight_total/weight_total)","metadata":{"_uuid":"cc3d187e-3f63-48f2-98b1-cf51af3341eb","_cell_guid":"43382437-c2a9-4b35-8334-b3124c18fbfa","collapsed":false,"execution":{"iopub.status.busy":"2022-09-10T03:42:57.277811Z","iopub.execute_input":"2022-09-10T03:42:57.278034Z","iopub.status.idle":"2022-09-10T03:42:57.285726Z","shell.execute_reply.started":"2022-09-10T03:42:57.277978Z","shell.execute_reply":"2022-09-10T03:42:57.284397Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}